nohup: ignoring input
Using 2 threads
22:14:50 INFO <module> (254) ======================================
22:14:50 INFO <module> (256) Config
22:14:50 INFO <module> (257) Namespace(balance_stage=5, batchsize=50, burnin=20, cold=False, debug=False, dim=10, distfn='poincare', dset='wordnet/noun_closure.tsv', dset_test='', epochs=1500, eval_each=100, fout='model/53nouns.lr=1.0.dim=10.negs=50.burnin=20.batch=50', lr=1.0, ndproc=2, negs=50, nn_hidden_layer=1, nn_hidden_size=50, nproc=2, override=False, symmetrize=False, w2v_nn=False, w2v_sim=False, word=False)

Indexing data
22:15:04 INFO <module> (310) json_conf: {"distfn": "poincare", "dim": 10, "lr": 1, "batchsize": 50, "negs": 50, "burnin": 20, "eval_each": 100}
22:15:04 INFO train (84) Burnin: lr=0.01
22:18:21 INFO control (143) json_log: {"epoch": 0, "loss": 1.790124410913026, "words_sim_loss": None, "elapsed": 197.06431199994404}
22:18:22 INFO train (84) Burnin: lr=0.01
22:21:43 INFO control (143) json_log: {"epoch": 1, "loss": 1.7872026565498114, "words_sim_loss": None, "elapsed": 200.72916600003373}
22:21:43 INFO train (84) Burnin: lr=0.01
22:25:01 INFO control (143) json_log: {"epoch": 2, "loss": 1.7843101775240342, "words_sim_loss": None, "elapsed": 197.86447200004477}
22:25:01 INFO train (84) Burnin: lr=0.01
22:28:14 INFO control (143) json_log: {"epoch": 3, "loss": 1.7813450880574275, "words_sim_loss": None, "elapsed": 192.3405920000514}
22:28:14 INFO train (84) Burnin: lr=0.01
22:31:38 INFO control (143) json_log: {"epoch": 4, "loss": 1.7783266916568274, "words_sim_loss": None, "elapsed": 204.1495860000141}
22:31:38 INFO train (84) Burnin: lr=0.01
22:35:26 INFO control (143) json_log: {"epoch": 5, "loss": 1.7752382232706185, "words_sim_loss": None, "elapsed": 227.2060529999435}
22:35:26 INFO train (84) Burnin: lr=0.01
22:39:01 INFO control (143) json_log: {"epoch": 6, "loss": 1.7721027203707336, "words_sim_loss": None, "elapsed": 214.8416600000346}
22:39:01 INFO train (84) Burnin: lr=0.01
22:43:00 INFO control (143) json_log: {"epoch": 7, "loss": 1.769030450266634, "words_sim_loss": None, "elapsed": 239.06686900008935}
22:43:01 INFO train (84) Burnin: lr=0.01
22:47:13 INFO control (143) json_log: {"epoch": 8, "loss": 1.765898658070714, "words_sim_loss": None, "elapsed": 252.23214600002393}
22:47:13 INFO train (84) Burnin: lr=0.01
22:50:46 INFO control (143) json_log: {"epoch": 9, "loss": 1.7627595756034995, "words_sim_loss": None, "elapsed": 213.16348700004164}
22:50:47 INFO train (84) Burnin: lr=0.01
22:54:19 INFO control (143) json_log: {"epoch": 10, "loss": 1.7595788906342793, "words_sim_loss": None, "elapsed": 212.34686900000088}
22:54:20 INFO train (84) Burnin: lr=0.01
22:57:44 INFO control (143) json_log: {"epoch": 11, "loss": 1.7564123146483595, "words_sim_loss": None, "elapsed": 204.5526499999687}
22:57:44 INFO train (84) Burnin: lr=0.01
23:01:19 INFO control (143) json_log: {"epoch": 12, "loss": 1.753240601040444, "words_sim_loss": None, "elapsed": 214.97433699993417}
23:01:20 INFO train (84) Burnin: lr=0.01
23:04:42 INFO control (143) json_log: {"epoch": 13, "loss": 1.7500019447429074, "words_sim_loss": None, "elapsed": 202.6574440000113}
23:04:43 INFO train (84) Burnin: lr=0.01
23:07:59 INFO control (143) json_log: {"epoch": 14, "loss": 1.7469081698588866, "words_sim_loss": None, "elapsed": 196.4913940000115}
23:08:00 INFO train (84) Burnin: lr=0.01
23:11:14 INFO control (143) json_log: {"epoch": 15, "loss": 1.7436900394085744, "words_sim_loss": None, "elapsed": 194.0447540000314}
23:11:14 INFO train (84) Burnin: lr=0.01
23:14:42 INFO control (143) json_log: {"epoch": 16, "loss": 1.7405169614470513, "words_sim_loss": None, "elapsed": 208.07279100001324}
23:14:43 INFO train (84) Burnin: lr=0.01
23:18:04 INFO control (143) json_log: {"epoch": 17, "loss": 1.7373549911892763, "words_sim_loss": None, "elapsed": 201.3692400000291}
23:18:04 INFO train (84) Burnin: lr=0.01
23:21:17 INFO control (143) json_log: {"epoch": 18, "loss": 1.734131344313449, "words_sim_loss": None, "elapsed": 193.07391700008884}
23:21:18 INFO train (84) Burnin: lr=0.01
23:24:34 INFO control (143) json_log: {"epoch": 19, "loss": 1.730758969699722, "words_sim_loss": None, "elapsed": 196.40043299994431}
23:28:11 INFO control (143) json_log: {"epoch": 20, "loss": 3.733281243041553, "words_sim_loss": None, "elapsed": 216.928486000048}
23:31:49 INFO control (143) json_log: {"epoch": 21, "loss": 3.4199589503242964, "words_sim_loss": None, "elapsed": 217.71116699988488}
23:35:37 INFO control (143) json_log: {"epoch": 22, "loss": 3.1194808518576953, "words_sim_loss": None, "elapsed": 227.13907400006428}
23:39:16 INFO control (143) json_log: {"epoch": 23, "loss": 2.851267380423091, "words_sim_loss": None, "elapsed": 218.8751260000281}
23:42:53 INFO control (143) json_log: {"epoch": 24, "loss": 2.615011248770159, "words_sim_loss": None, "elapsed": 216.5320050000446}
23:46:32 INFO control (143) json_log: {"epoch": 25, "loss": 2.407676267336747, "words_sim_loss": None, "elapsed": 218.51955600001384}
23:50:10 INFO control (143) json_log: {"epoch": 26, "loss": 2.2110548100021035, "words_sim_loss": None, "elapsed": 218.2656029999489}
23:53:46 INFO control (143) json_log: {"epoch": 27, "loss": 2.0354999316491056, "words_sim_loss": None, "elapsed": 215.47541700000875}
23:57:21 INFO control (143) json_log: {"epoch": 28, "loss": 1.8941620874334322, "words_sim_loss": None, "elapsed": 214.75411800004076}
00:00:56 INFO control (143) json_log: {"epoch": 29, "loss": 1.7624519444654165, "words_sim_loss": None, "elapsed": 214.49891399999615}
00:04:32 INFO control (143) json_log: {"epoch": 30, "loss": 1.6534585196130323, "words_sim_loss": None, "elapsed": 215.72261799999978}
00:08:10 INFO control (143) json_log: {"epoch": 31, "loss": 1.5356931159336207, "words_sim_loss": None, "elapsed": 217.53367899998557}
00:11:48 INFO control (143) json_log: {"epoch": 32, "loss": 1.424810365839034, "words_sim_loss": None, "elapsed": 218.05035699997097}
00:15:31 INFO control (143) json_log: {"epoch": 33, "loss": 1.334274031940756, "words_sim_loss": None, "elapsed": 222.84346600004937}
00:19:12 INFO control (143) json_log: {"epoch": 34, "loss": 1.250205704007138, "words_sim_loss": None, "elapsed": 219.77031599998008}
00:22:50 INFO control (143) json_log: {"epoch": 35, "loss": 1.167014873989529, "words_sim_loss": None, "elapsed": 218.23126000002958}
00:26:31 INFO control (143) json_log: {"epoch": 36, "loss": 1.089347645445862, "words_sim_loss": None, "elapsed": 220.92090599995572}
00:30:13 INFO control (143) json_log: {"epoch": 37, "loss": 1.0151898327529583, "words_sim_loss": None, "elapsed": 221.06331600004341}
00:33:55 INFO control (143) json_log: {"epoch": 38, "loss": 0.9473054648255808, "words_sim_loss": None, "elapsed": 221.42975000001024}
00:37:35 INFO control (143) json_log: {"epoch": 39, "loss": 0.8840788776986677, "words_sim_loss": None, "elapsed": 219.7759570000926}
00:41:21 INFO control (143) json_log: {"epoch": 40, "loss": 0.8252642349285002, "words_sim_loss": None, "elapsed": 226.21996800007764}
00:45:09 INFO control (143) json_log: {"epoch": 41, "loss": 0.7710690627852386, "words_sim_loss": None, "elapsed": 227.77578499994706}
00:48:52 INFO control (143) json_log: {"epoch": 42, "loss": 0.7206560468055281, "words_sim_loss": None, "elapsed": 222.1932079999242}
00:52:36 INFO control (143) json_log: {"epoch": 43, "loss": 0.6754356976786495, "words_sim_loss": None, "elapsed": 224.11344799993094}
00:56:20 INFO control (143) json_log: {"epoch": 44, "loss": 0.6338198900306999, "words_sim_loss": None, "elapsed": 223.30885899998248}
01:00:12 INFO control (143) json_log: {"epoch": 45, "loss": 0.5949237026006501, "words_sim_loss": None, "elapsed": 232.09850600000937}
01:04:45 INFO control (143) json_log: {"epoch": 46, "loss": 0.5587938148611055, "words_sim_loss": None, "elapsed": 272.492631000001}
01:08:24 INFO control (143) json_log: {"epoch": 47, "loss": 0.5282097551823786, "words_sim_loss": None, "elapsed": 218.77453199995216}
01:12:39 INFO control (143) json_log: {"epoch": 48, "loss": 0.4967399736225421, "words_sim_loss": None, "elapsed": 254.27633999998216}
01:16:57 INFO control (143) json_log: {"epoch": 49, "loss": 0.47060995374404796, "words_sim_loss": None, "elapsed": 257.53172999992967}
01:21:13 INFO control (143) json_log: {"epoch": 50, "loss": 0.4442349784492307, "words_sim_loss": None, "elapsed": 256.0452090000035}
01:25:01 INFO control (143) json_log: {"epoch": 51, "loss": 0.4221094734249871, "words_sim_loss": None, "elapsed": 227.2863709999947}
01:28:45 INFO control (143) json_log: {"epoch": 52, "loss": 0.4018806534259208, "words_sim_loss": None, "elapsed": 223.1524409999838}
01:32:25 INFO control (143) json_log: {"epoch": 53, "loss": 0.381674035935451, "words_sim_loss": None, "elapsed": 220.13966400001664}
01:36:40 INFO control (143) json_log: {"epoch": 54, "loss": 0.3647963214666153, "words_sim_loss": None, "elapsed": 254.87951999995857}
01:40:27 INFO control (143) json_log: {"epoch": 55, "loss": 0.34933812966911904, "words_sim_loss": None, "elapsed": 226.6804059999995}
01:44:42 INFO control (143) json_log: {"epoch": 56, "loss": 0.3330025475233083, "words_sim_loss": None, "elapsed": 254.24104100000113}
01:48:18 INFO control (143) json_log: {"epoch": 57, "loss": 0.3196600290119865, "words_sim_loss": None, "elapsed": 215.80793999996968}
01:51:57 INFO control (143) json_log: {"epoch": 58, "loss": 0.30594969033100067, "words_sim_loss": None, "elapsed": 218.15781600004993}
01:55:44 INFO control (143) json_log: {"epoch": 59, "loss": 0.2940663738408587, "words_sim_loss": None, "elapsed": 227.21741799998563}
01:59:31 INFO control (143) json_log: {"epoch": 60, "loss": 0.28250944123018995, "words_sim_loss": None, "elapsed": 226.0107610000996}
02:03:59 INFO control (143) json_log: {"epoch": 61, "loss": 0.27282376209547904, "words_sim_loss": None, "elapsed": 267.8288419999881}
02:08:16 INFO control (143) json_log: {"epoch": 62, "loss": 0.26303036629004634, "words_sim_loss": None, "elapsed": 257.23239899997134}
02:12:16 INFO control (143) json_log: {"epoch": 63, "loss": 0.2540943149290252, "words_sim_loss": None, "elapsed": 238.7970379999606}
02:16:51 INFO control (143) json_log: {"epoch": 64, "loss": 0.2446735325437217, "words_sim_loss": None, "elapsed": 274.6297309999354}
02:21:06 INFO control (143) json_log: {"epoch": 65, "loss": 0.23808492851923474, "words_sim_loss": None, "elapsed": 254.6037629999919}
02:25:43 INFO control (143) json_log: {"epoch": 66, "loss": 0.2292269103824611, "words_sim_loss": None, "elapsed": 277.04785099998116}
02:30:32 INFO control (143) json_log: {"epoch": 67, "loss": 0.2228481301185846, "words_sim_loss": None, "elapsed": 288.39122200000565}
02:34:19 INFO control (143) json_log: {"epoch": 68, "loss": 0.2152538023374713, "words_sim_loss": None, "elapsed": 227.09487999998964}
02:39:00 INFO control (143) json_log: {"epoch": 69, "loss": 0.2093092755070767, "words_sim_loss": None, "elapsed": 279.9975240000058}
02:44:20 INFO control (143) json_log: {"epoch": 70, "loss": 0.20412063779758824, "words_sim_loss": None, "elapsed": 320.4418930000393}
02:49:35 INFO control (143) json_log: {"epoch": 71, "loss": 0.1988184115547517, "words_sim_loss": None, "elapsed": 314.2975059999153}
02:55:06 INFO control (143) json_log: {"epoch": 72, "loss": 0.1931634421014534, "words_sim_loss": None, "elapsed": 330.49384500004817}
03:00:42 INFO control (143) json_log: {"epoch": 73, "loss": 0.1869406046927609, "words_sim_loss": None, "elapsed": 335.45099200005643}
03:06:08 INFO control (143) json_log: {"epoch": 74, "loss": 0.18317052273247944, "words_sim_loss": None, "elapsed": 325.58813599997666}
03:10:21 INFO control (143) json_log: {"epoch": 75, "loss": 0.17923394935272002, "words_sim_loss": None, "elapsed": 252.35381899995264}
03:15:26 INFO control (143) json_log: {"epoch": 76, "loss": 0.17411376511177534, "words_sim_loss": None, "elapsed": 305.3846710000653}
03:20:21 INFO control (143) json_log: {"epoch": 77, "loss": 0.17057985821750118, "words_sim_loss": None, "elapsed": 294.51970599999186}
03:24:44 INFO control (143) json_log: {"epoch": 78, "loss": 0.16720553515111752, "words_sim_loss": None, "elapsed": 262.2489910000004}
03:29:22 INFO control (143) json_log: {"epoch": 79, "loss": 0.16407500418980148, "words_sim_loss": None, "elapsed": 277.39658900001086}
03:33:18 INFO control (143) json_log: {"epoch": 80, "loss": 0.16022504891289338, "words_sim_loss": None, "elapsed": 235.80321499996353}
03:37:21 INFO control (143) json_log: {"epoch": 81, "loss": 0.15677597431250168, "words_sim_loss": None, "elapsed": 242.54099100001622}
03:41:51 INFO control (143) json_log: {"epoch": 82, "loss": 0.15375726859775452, "words_sim_loss": None, "elapsed": 269.9127850000514}
03:45:44 INFO control (143) json_log: {"epoch": 83, "loss": 0.15081340419646147, "words_sim_loss": None, "elapsed": 232.3842289999593}
03:49:23 INFO control (143) json_log: {"epoch": 84, "loss": 0.14799435572607722, "words_sim_loss": None, "elapsed": 218.59519899997395}
03:53:38 INFO control (143) json_log: {"epoch": 85, "loss": 0.14526868540763077, "words_sim_loss": None, "elapsed": 254.53892299998552}
03:57:14 INFO control (143) json_log: {"epoch": 86, "loss": 0.1432968731107329, "words_sim_loss": None, "elapsed": 216.25456000003032}
04:02:05 INFO control (143) json_log: {"epoch": 87, "loss": 0.14054533753400214, "words_sim_loss": None, "elapsed": 290.91828300000634}
04:05:55 INFO control (143) json_log: {"epoch": 88, "loss": 0.13760227456743024, "words_sim_loss": None, "elapsed": 228.8795449999161}
04:11:03 INFO control (143) json_log: {"epoch": 89, "loss": 0.13565112600062162, "words_sim_loss": None, "elapsed": 308.37506999995094}
04:15:37 INFO control (143) json_log: {"epoch": 90, "loss": 0.13366628629461888, "words_sim_loss": None, "elapsed": 273.06586099998094}
04:19:22 INFO control (143) json_log: {"epoch": 91, "loss": 0.1313986788626523, "words_sim_loss": None, "elapsed": 224.85093399998732}
04:23:14 INFO control (143) json_log: {"epoch": 92, "loss": 0.12840624353288801, "words_sim_loss": None, "elapsed": 231.04650199995376}
04:27:49 INFO control (143) json_log: {"epoch": 93, "loss": 0.12674341370796408, "words_sim_loss": None, "elapsed": 275.5041740000015}
04:32:15 INFO control (143) json_log: {"epoch": 94, "loss": 0.12514922254177543, "words_sim_loss": None, "elapsed": 265.1371560000116}
04:36:03 INFO control (143) json_log: {"epoch": 95, "loss": 0.1234577799990699, "words_sim_loss": None, "elapsed": 227.81783999991603}
04:39:41 INFO control (143) json_log: {"epoch": 96, "loss": 0.12193744128705065, "words_sim_loss": None, "elapsed": 217.3946650000289}
04:43:26 INFO control (143) json_log: {"epoch": 97, "loss": 0.12032716762103554, "words_sim_loss": None, "elapsed": 224.47378600004595}
04:47:12 INFO control (143) json_log: {"epoch": 98, "loss": 0.11821021969201924, "words_sim_loss": None, "elapsed": 226.17780100007076}
04:51:28 INFO control (104) Saving model fmodel/53nouns.lr=1.0.dim=10.negs=50.burnin=20.batch=50/99.nth
Sense Level
Process Process-4:
Traceback (most recent call last):
  File "/home/chen/anaconda3/lib/python3.6/multiprocessing/process.py", line 258, in _bootstrap
    self.run()
  File "/home/chen/anaconda3/lib/python3.6/multiprocessing/process.py", line 93, in run
    self._target(*self._args, **self._kwargs)
  File "embed.py", line 105, in control
    log.info(f'Saving model f{_fout}')
  File "embed.py", line 86, in eval_human
    ev = Evaluator(_model.embedding(), objs, word_index=word_index)
  File "/mnt/c/Users/Administrator/Documents/G/poincare-embeddings/evaluation.py", line 83, in evaluate
    try:
  File "/mnt/c/Users/Administrator/Documents/G/poincare-embeddings/evaluation.py", line 82, in <listcomp>
    if self.word2vec is None:
  File "/mnt/c/Users/Administrator/Documents/G/poincare-embeddings/sematch/evaluation.py", line 310, in evaluate_metric
    sim_values = [sim_func(w1, w2) for w1, w2 in word_pairs]
  File "/mnt/c/Users/Administrator/Documents/G/poincare-embeddings/sematch/evaluation.py", line 310, in <listcomp>
    sim_values = [sim_func(w1, w2) for w1, w2 in word_pairs]
  File "/mnt/c/Users/Administrator/Documents/G/poincare-embeddings/evaluation.py", line 81, in sim
    if is_word_level:
  File "/mnt/c/Users/Administrator/Documents/G/poincare-embeddings/sematch/utility.py", line 79, in __call__
    value = self.func(*args)
  File "/mnt/c/Users/Administrator/Documents/G/poincare-embeddings/evaluation.py", line 92, in word_similarity
    return self.word_similarity(x, y, method)
  File "/mnt/c/Users/Administrator/Documents/G/poincare-embeddings/evaluation.py", line 133, in max_synset_similarity
    return _sim
  File "/mnt/c/Users/Administrator/Documents/G/poincare-embeddings/evaluation.py", line 133, in <listcomp>
    return _sim
  File "/mnt/c/Users/Administrator/Documents/G/poincare-embeddings/evaluation.py", line 110, in sim
    s1 = self.word2synset(w1)
  File "/mnt/c/Users/Administrator/Documents/G/poincare-embeddings/evaluation.py", line 123, in get_dist
    def syn_similarity_gen(self, dist2sim):
RuntimeError: expected a Variable argument, but got numpy.ndarray
04:55:43 ERROR train_mp (33) [Errno 32] Broken pipe
Traceback (most recent call last):
  File "/mnt/c/Users/Administrator/Documents/G/poincare-embeddings/train.py", line 31, in train_mp
    train(model, data, optimizer, opt, log, rank, queue, w_head, w_neg)
  File "/mnt/c/Users/Administrator/Documents/G/poincare-embeddings/train.py", line 104, in train
    (epoch, elapsed, np.mean(epoch_loss), emb, None)
  File "<string>", line 2, in put
  File "/home/chen/anaconda3/lib/python3.6/multiprocessing/managers.py", line 756, in _callmethod
    conn.send((self._id, methodname, args, kwds))
  File "/home/chen/anaconda3/lib/python3.6/multiprocessing/connection.py", line 206, in send
    self._send_bytes(_ForkingPickler.dumps(obj))
  File "/home/chen/anaconda3/lib/python3.6/multiprocessing/connection.py", line 404, in _send_bytes
    self._send(header + buf)
  File "/home/chen/anaconda3/lib/python3.6/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
Process Process-2:
Traceback (most recent call last):
  File "/mnt/c/Users/Administrator/Documents/G/poincare-embeddings/train.py", line 31, in train_mp
    train(model, data, optimizer, opt, log, rank, queue, w_head, w_neg)
  File "/mnt/c/Users/Administrator/Documents/G/poincare-embeddings/train.py", line 104, in train
    (epoch, elapsed, np.mean(epoch_loss), emb, None)
  File "<string>", line 2, in put
  File "/home/chen/anaconda3/lib/python3.6/multiprocessing/managers.py", line 756, in _callmethod
    conn.send((self._id, methodname, args, kwds))
  File "/home/chen/anaconda3/lib/python3.6/multiprocessing/connection.py", line 206, in send
    self._send_bytes(_ForkingPickler.dumps(obj))
  File "/home/chen/anaconda3/lib/python3.6/multiprocessing/connection.py", line 404, in _send_bytes
    self._send(header + buf)
  File "/home/chen/anaconda3/lib/python3.6/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/chen/anaconda3/lib/python3.6/multiprocessing/process.py", line 258, in _bootstrap
    self.run()
  File "/home/chen/anaconda3/lib/python3.6/multiprocessing/process.py", line 93, in run
    self._target(*self._args, **self._kwargs)
  File "/mnt/c/Users/Administrator/Documents/G/poincare-embeddings/train.py", line 34, in train_mp
    queue.put(None)
  File "<string>", line 2, in put
  File "/home/chen/anaconda3/lib/python3.6/multiprocessing/managers.py", line 756, in _callmethod
    conn.send((self._id, methodname, args, kwds))
  File "/home/chen/anaconda3/lib/python3.6/multiprocessing/connection.py", line 206, in send
    self._send_bytes(_ForkingPickler.dumps(obj))
  File "/home/chen/anaconda3/lib/python3.6/multiprocessing/connection.py", line 404, in _send_bytes
    self._send(header + buf)
  File "/home/chen/anaconda3/lib/python3.6/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
